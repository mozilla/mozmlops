{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb0ca0-c6fc-43f1-a21b-5026867cac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install mozmlops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef07b0-3292-4c5f-8ca1-4e80ce1b2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Source Code Form is subject to the terms of the Mozilla Public\n",
    "# License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "# file, You can obtain one at https://mozilla.org/MPL/2.0/.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define an image classifier model (CNN)\n",
    "class ImageClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281ad02-f4cb-489e-bf47-8d318f13e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Source Code Form is subject to the terms of the Mozilla Public\n",
    "# License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "# file, You can obtain one at https://mozilla.org/MPL/2.0/.\n",
    "\n",
    "import os\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    Parameter,\n",
    "    card,\n",
    "    current,\n",
    "    step,\n",
    "    environment,\n",
    "    kubernetes,\n",
    "    pypi,\n",
    "    nvidia,\n",
    ")\n",
    "from metaflow.cards import Markdown\n",
    "\n",
    "# Set the right GCP project and GCS bucket\n",
    "GCS_PROJECT_NAME = \"your-gcp-project-here\"\n",
    "GCS_BUCKET_NAME = \"your-gcs-bucket-here\"\n",
    "# Model blob to be uploaded to GCS\n",
    "MODEL_STORAGE_PATH = \"image_classifier/trained-model-bytes.pth\"\n",
    "\n",
    "\n",
    "class ImageClassifierFlow(FlowSpec):\n",
    "    # This is an example of a parameter. You can toggle this when you call the flow\n",
    "    # with python template_flow.py run --offline False\n",
    "    offline_wandb = Parameter(\n",
    "        \"offline\",\n",
    "        help=\"Do not connect to W&B servers when training\",\n",
    "        type=bool,\n",
    "        default=True,\n",
    "    )\n",
    "\n",
    "    @pypi(python=\"3.11.9\", packages={\"torchvision\": \"0.19.1\"})\n",
    "    @card(type=\"default\")\n",
    "    @kubernetes\n",
    "    @step\n",
    "    def start(self):\n",
    "        import torchvision\n",
    "        import torchvision.transforms as transforms\n",
    "\n",
    "        # Download and normalize CIFAR10\n",
    "        print(\"start step: downloading and normalizing dataset\")\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.trainset = torchvision.datasets.CIFAR10(\n",
    "            root=\"./data\", train=True, download=True, transform=transform\n",
    "        )\n",
    "        self.testset = torchvision.datasets.CIFAR10(\n",
    "            root=\"./data\", train=False, download=True, transform=transform\n",
    "        )\n",
    "        self.next(self.train)\n",
    "\n",
    "    # Train the network\n",
    "    # Keep @nvidia decorator before @step decorator else the flow fails\n",
    "    @pypi(\n",
    "        python=\"3.11.9\",\n",
    "        packages={\"torch\": \"2.4.1\", \"torchvision\": \"0.19.1\", \"mozmlops\": \"0.1.4\"},\n",
    "    )\n",
    "    @nvidia\n",
    "    # @kubernetes\n",
    "    @card\n",
    "    @environment(\n",
    "        vars={\n",
    "            \"WANDB_API_KEY\": os.getenv(\"WANDB_API_KEY\"),\n",
    "            \"WANDB_PROJECT\": os.getenv(\"WANDB_PROJECT\"),\n",
    "        }\n",
    "    )\n",
    "    @step\n",
    "    def train(self):\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        import torch.optim as optim\n",
    "        from image_classifier_model import ImageClassifierModel\n",
    "        from io import BytesIO\n",
    "        import wandb\n",
    "        import os\n",
    "\n",
    "        if not self.offline_wandb:\n",
    "            tracking_run = wandb.init(project=os.getenv(\"WANDB_PROJECT\"))\n",
    "            wandb_url = tracking_run.get_url()\n",
    "            current.card.append(Markdown(\"# Weights & Biases\"))\n",
    "            current.card.append(\n",
    "                Markdown(f\"Your training run is tracked [here]({wandb_url}).\")\n",
    "            )\n",
    "\n",
    "        device = torch.device(\"cpu\")\n",
    "        # Check if GPU is available\n",
    "        if torch.cuda.is_available():\n",
    "            import os\n",
    "\n",
    "            print(os.system(\"nvidia-smi\"))\n",
    "            device = torch.device(\"cuda\")\n",
    "\n",
    "        print(f\"Training on: {device}\")\n",
    "\n",
    "        image_classifier_model = ImageClassifierModel().to(device)\n",
    "\n",
    "        # Define a Loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(\n",
    "            image_classifier_model.parameters(), lr=0.001, momentum=0.9\n",
    "        )\n",
    "\n",
    "        # Load train data\n",
    "        batch_size = 4\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "        )\n",
    "\n",
    "        # Start training\n",
    "        num_epochs = 2\n",
    "        for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = image_classifier_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                    print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "                    # log metrics to wandb\n",
    "                    wandb.log({\"mini-batches\": {i + 1}, \"loss\": {running_loss / 2000}})\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print(\"Finished Training\")\n",
    "        buffer = BytesIO()\n",
    "        torch.save(image_classifier_model.state_dict(), buffer)\n",
    "        self.model_state_dict_bytes = buffer.getvalue()\n",
    "        self.next(self.evaluate)\n",
    "\n",
    "    # Test the model on the test data\n",
    "    @pypi(\n",
    "        python=\"3.11.9\",\n",
    "        packages={\n",
    "            \"torch\": \"2.4.1\",\n",
    "            \"torchvision\": \"0.19.1\",\n",
    "        },\n",
    "    )\n",
    "    @kubernetes\n",
    "    @step\n",
    "    def evaluate(self):\n",
    "        import torch\n",
    "        from image_classifier_model import ImageClassifierModel\n",
    "        from io import BytesIO\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Evaluating on: {device}\")\n",
    "\n",
    "        image_classifier_model = ImageClassifierModel().to(device)\n",
    "        buffer = BytesIO(self.model_state_dict_bytes)\n",
    "        image_classifier_model.load_state_dict(\n",
    "            torch.load(buffer, map_location=device, weights_only=True)\n",
    "        )\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # load test data\n",
    "        batch_size = 4\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    "        )\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = image_classifier_model(images)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(\n",
    "            f\"Accuracy of the network on the 10000 test images: {100 * correct // total} %\"\n",
    "        )\n",
    "        self.next(self.upload_model_to_gcs)\n",
    "\n",
    "    @pypi(python=\"3.11.9\", packages={\"mozmlops\": \"0.1.4\"})\n",
    "    @kubernetes\n",
    "    @step\n",
    "    def upload_model_to_gcs(self):\n",
    "        from mozmlops.cloud_storage_api_client import CloudStorageAPIClient\n",
    "\n",
    "        print(\"Uploading model to gcs\")\n",
    "        # init client\n",
    "        storage_client = CloudStorageAPIClient(\n",
    "            project_name=GCS_PROJECT_NAME, bucket_name=GCS_BUCKET_NAME\n",
    "        )\n",
    "        storage_client.store(\n",
    "            data=self.model_state_dict_bytes, storage_path=MODEL_STORAGE_PATH\n",
    "        )\n",
    "        self.next(self.end)\n",
    "\n",
    "    @kubernetes\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\n",
    "            f\"\"\"\n",
    "            Flow complete.\n",
    "\n",
    "            See artifacts at {GCS_BUCKET_NAME}.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ImageClassifierFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de256cc-fecb-4e77-8a91-8b93d70732c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow\n",
    "\n",
    "run = Flow('MyFlow').latest_successful_run\n",
    "print(run.data.processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb040c03-7109-4185-9d13-1aa40f7e643e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bb880-184d-489e-81f8-7f7f8364deef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
